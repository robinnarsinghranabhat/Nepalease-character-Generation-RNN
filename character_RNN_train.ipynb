{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD THE TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD THE TRAIN AND TEST\n",
    "X = np.load('x_train_data.npy')\n",
    "y = np.load('y_validate_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DICTIONAIRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('char_to_ix.pickle', 'rb') as handle:\n",
    "    char_to_ix = pickle.load(handle)\n",
    "with open('ix_to_char.pickle', 'rb') as handle:\n",
    "    ix_to_char = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'म'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix_to_char[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 120\n",
    "VOCAB_SIZE = 87"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN THE DATA (Currently , to see how training works , take epoch to 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glob/intel-python/versions/2018u2/intelpython3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model,load_model\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM, Input, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import LambdaCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SEQ_LENGTH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-818c4db9b77b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mSEQ_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SEQ_LENGTH' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add( LSTM(256,return_sequences= True , input_shape = [SEQ_LENGTH,VOCAB_SIZE]) )\n",
    "model.add(LSTM(256,input_shape = (None,VOCAB_SIZE),return_sequences=True))\n",
    "\n",
    "model.add(Dropout(0.6))\n",
    "model.add(TimeDistributed(Dense(VOCAB_SIZE)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE : INPUT TO MODEL IS BATCH of CHARACTERS , where each sequence is of 120\n",
    "# OUPTUT OF MODEL IS 120 characters, each represented as one hot vectors of 86 zeros and single 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET CALLBACK TO PRINT MODEL OUTPUT AT EACH EPOCH\n",
    "def on_epoch_end(epoch,logs):\n",
    "    SEQ_LENGTH = 120\n",
    "    VOCAB_SIZE = 87\n",
    "    print('\\n')\n",
    "    print(\"---generating text after epoch using USELESS function: \", epoch)\n",
    "    print('\\n')\n",
    "    file1 = open('another_function_text.txt','a')\n",
    "    file1.write('\\n')\n",
    "    file1.write('--------------------sampe {} -----------------'.format(epoch))\n",
    "    file1.write('\\n')\n",
    "    ix = [np.random.randint(VOCAB_SIZE)]\n",
    "    y_char = [ix_to_char[ix[-1]]]\n",
    "    hold = np.zeros((1, SEQ_LENGTH, VOCAB_SIZE))\n",
    "    ix = ix[-1]\n",
    "    for i in range(120):\n",
    "        print(ix_to_char[ix], end = \"\")\n",
    "        hold[0, i, :][ix] = 1\n",
    "        ix = np.argmax(model.predict(hold[:, :, :])[0][i], 0)\n",
    "        y_char.append(ix_to_char[ix])\n",
    "    text = ('').join(y_char)\n",
    "    file1.write(text)\n",
    "\n",
    "    file1.write('-------------------END OF {} SAMPLE--------------------'.format(epoch)+'\\n')\n",
    "    print('\\n')\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR NOW , LET's USE A TRAINED MODEL, as TRAINING TAKES SIGNIFICANT TIME\n",
    "\n",
    "# epochs = 50\n",
    "# batch_size = 64\n",
    "\n",
    "# print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "# callbacks=[EarlyStopping(patience=4, monitor='val_loss'),print_callback,\n",
    "#            ModelCheckpoint(filepath=\"/home/u8217/lstmShakes/RNN_Text_Generation_Tensorflow-master/news_total_model-{epoch:02d}-{val_acc:.2f}.h5\" , \n",
    "#            monitor='val_loss', verbose=1, mode='auto',period=4,save_weights_only = False)]\n",
    "\n",
    "# model.fit(X,y,validation_split=0.1,batch_size= batch_size ,callbacks=callbacks,epochs=epochs)\n",
    "# model.save('final_model_news_generator.h5')\n",
    "\n",
    "# model.fit(X,y,batch_size= batch_size,verbose= 1,epochs = 50 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD TRAINED MODEL\n",
    "trainedM = load_model('corrected_news-16-0.59.h5',compile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERATE TEXT USING OUR LANGUAGE GENERATION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_txt(model):\n",
    "    \n",
    "#     randSeed = X[np.random.randint(0,VOCAB_SIZE)]\n",
    "#     charlist = [ix_to_char[i] for i in np.argmax(randSeed,axis = 1) ] \n",
    "    \n",
    "#     print('...........SEED TEXT.............')\n",
    "#     seed_text = \"\".join(charlist)\n",
    "#     print(seed_text)\n",
    "#     print('\\n')\n",
    "   \n",
    "#     pattern = randSeed.reshape((1,SEQ_LENGTH,VOCAB_SIZE))\n",
    "#     for i in range(200):\n",
    "#         prediction = model.predict(pattern)\n",
    "#         myword = prediction[:,-1,:]\n",
    "        \n",
    "#         wordind = np.argmax(myword)\n",
    "#         print(ix_to_char[wordind], end = \"\")\n",
    "#         lastpred  = myword.reshape(1,1,VOCAB_SIZE)\n",
    "#         charlist.append(ix_to_char[wordind])\n",
    "#         pattern = np.hstack((pattern[:,1:,:],lastpred))\n",
    "# #         pattern = pattern[:,i+1:SEQ_LENGTH+i+1,: ]\n",
    "#     ('').join(charlist)\n",
    "\n",
    "\n",
    "# CODE FOR GENEARTING NEW TEXT FROM MODEL\n",
    "def generate_text(model, length= 120,seedStart = 'स',seed = False):\n",
    "    if seed :\n",
    "        ix = [char_to_ix[seedStart]]\n",
    "    else :\n",
    "        ix = [np.random.randint(VOCAB_SIZE)]\n",
    "    y_char = [ix_to_char[ix[-1]]]\n",
    "    X = np.zeros((1, length, VOCAB_SIZE))\n",
    "    ix = ix[-1]\n",
    "    for i in range(120):\n",
    "        print(ix_to_char[ix], end=\"\")\n",
    "        X[0, i, :][ix] = 1\n",
    "        ix = np.argmax(model.predict(X[:, :, :])[0][i], 0)\n",
    "        y_char.append(ix_to_char[ix])\n",
    "    return ('').join(y_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "वास स्थापना गरेको छ                                                                                                     "
     ]
    },
    {
     "data": {
      "text/plain": [
       "'वास स्थापना गरेको छ                                                                                                      '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(trainedM,seedStart='व',seed = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "स्थान गर्ने कारण प्रतिक्रिया दिएका छन्                                                                                  "
     ]
    },
    {
     "data": {
      "text/plain": [
       "'स्थान गर्ने कारण प्रतिक्रिया दिएका छन्                                                                                   '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(trainedM,seedStart='स',seed = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our lstm cells learned to generate new characters completely on their own, given a input starting point.\n",
    "If you observe carefully , you will see the sentence actually makes sense.\n",
    "Since we used news article , we get similar vibe from this generated text. \n",
    "I trained the model in a smaller dataset for just 24 epochs. Training took 4 hours . So, Basically , You need to train on a lot bigger dataset for model to be more perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel, 2018 update 2)",
   "language": "python",
   "name": "intel_distribution_of_python_3_2018u2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
